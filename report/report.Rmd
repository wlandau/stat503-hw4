---
title: "STAT 503 Homework 4: STAT 101 Grades"
author: "Andee Kaplan, Will Landau, Fangge Liu, Lindsay Rutter"
date: "March 27, 2015"
output:
  pdf_document:
    fig_caption: true
bibliography: report.bib
---

```{r hooks, echo = F}
knitr::opts_chunk$set(echo = F, cache = T, message = F, warning = F)
```

#Introduction

STAT 101 course instructors at Iowa State University usually claim their students are diverse. The undergrads who sign up have a wide variety of majors, backgrounds, perspectives, abilities, and levels of motivation. Visual and unsupervised analyses of homework grades may classify students in useful, insightful ways and even inform pedagogy.

We have three homework grade spreadsheets, each of which comes directly from Blackboard [@blackboard], Iowa State's system for managing course materials and grades. Each dataset corresponds to a single semester of STAT 101: either fall 2013, fall 2014, or spring 2014. Each semester has six or seven sections of roughly one hundred students each. Every spreadsheet has roughly twenty variables, each of which corresponds to a homework grade (either percentage of points earned or NA for a missing assignment) or the average homework score with missing assignments removed.

#Missing values

A large fraction of homework scores appear as "NA", or missing. Since the spreadsheets come directly from Blackboard, we assume that almost all NA's correspond to homeworks that students failed to turn in, and only a small number, if any, are from bookkeeping errors. Before clustering, we need to impute these values, and for an imputation strategy, we look at patterns of missingness. 

###Visual patterns in missing values

Figure \ref{fig:missingHist} plots the number of missing values per student for all students. Most of the students missed few to no assignments, and some students missed several. This pattern is consistent with each semester and section. Figure \ref{fig:missingByAssign} shows the number of missing values for each assignment within each semester and section. For the fall semesters, notable spikes occur at chapter 9 ("Understanding Randomness") and topic 9 ("Sample Surveys"). Otherwise, for most sections, the number of missings increased steadily for each section over time.

Figures \ref{fig:missingBarcodesFall13}, \ref{fig:missingBarcodesFall14}, and \ref{fig:missingBarcodesSpring14} show each student's pattern of missingness. General patterns are consistent. Most students had few missing assignments scattered sporadically over the semester, some students dropped the class early, and a smaller students missed strings of around five or ten consecutive assignments in the beginning, middle, or end of the semester.


```{r missing-vis.R}
source("../R/missing-vis.R")
```

```{r missingHist,  fig.cap="\\label{fig:missingHist} number of missing values per student for all students. The top right panel facets by semester, and the bottom left panel facets by semester and section number. Most of the students missed few to zero assignments, and some students missed several. This pattern is consistent with each semester and section."}
missingHist()
```


```{r missingByAssign, fig.cap="\\label{fig:missingByAssign} number of missing values per assignment for each semester and section. For the fall semesters, notable spikes occur at chapter 9 (\"Understanding Randomness\") and topic 9 (\"Sample Surveys\"). Otherwise, for most sections, the number of missings increased steadily for each section over time."}
missingByAssign()
```

```{r missingBarcodesFall13, fig.cap="\\label{fig:missingBarcodesFall13} missing assignment records for fall 2013 students faceted by section number. Each row represents a student, each column is an assignment, and the tiles are colored according to the status of the corresponding assignment (missing or turned in). General patterns are consistent across section number. Most students missed few assignments, and the students with the most missings usually missed the last fifteen assignments. These students most likely dropped the class early."}
missingBarcodesFall13()
```

```{r missingBarcodesFall14, fig.cap="\\label{fig:missingBarcodesFall14} Same as Figure \\ref{fig:missingBarcodesFall13}, but for fall 2014. We see some early drops, but also some students who failed to turn in either the first few or the middle few assignments."}
missingBarcodesFall14()
```

```{r missingBarcodesSpring14, fig.cap="\\label{fig:missingBarcodesSpring14} Same as Figure \\ref{fig:missingBarcodesFall13}, but for spring 2014. Patterns are similar to those of Figure \\ref{fig:missingBarcodesFall13} (fall 2013)."}
missingBarcodesSpring14()
```

###Grouping students by missingness

From inspection, we can partition the students in each semester into four groups.

Group 1 contains students who did not submit all of the last nine (about half) of all homework assignments. Group 2 contains students (who were not in Group 1) and missed at least nine (about half) of all homework assignments. Group 3 contains students (who were not in Group 1 or 2) and missed at least one homework assignment. Group 4 contains students (who were not in Group 1, 2, or 3) who did not miss any homework assignments.

As a result, we generated 12 main groups (the four groups across three semesters), as shown in Table \ref{tab:MainGroups}.  

```{r GeneralMissingClusters}
source("../R/GeneralMissingClusters.R")
```


```{r, message=FALSE, echo=FALSE}
library(knitr)
library(dplyr)
library(ggplot2)

grp <- matrix(c(nrow(Fall13_G1),nrow(Fall13_G2),nrow(Fall13_G3),nrow(Fall13_G4), nrow(Spring14_G1),nrow(Spring14_G2),nrow(Spring14_G3),nrow(Spring14_G4),nrow(Fall14_G1),nrow(Fall14_G2),nrow(Fall14_G3),nrow(Fall14_G4)), ncol=3)
colnames(grp) <- c('Fall 13', 'Spring 14', 'Fall 14')
rownames(grp) <- c('Group 1 - Drop outs', 'Group 2 - Common missings', 'Group 3 - Sporadic missings', 'Group 4 - No missings')
grp.table <- as.table(grp)

grp.table %>%
  kable(caption = "\\label{tab:MainGroups}The number of students who were categorized into one of four mutually-exclusive groups, for the three semesters. We considered Groups 1 and 2 to be problematic, as they likely represented students who dropped the course or habitually missed assignments. However, even after removing students from Groups 1 and 2, we are still left with a very large dataset to cluster")
```

### Trim and impute

As we explain above, groups 1 and 2 are relatively small, and the students in these groups missed at least half of the homework assignments. With good reason, we give each of these groups its own cluster and concentrate the rest of our analysis on groups 3 and 4 only. These remaining students have some missing values left, and we impute them with the nearest neighbors imputation functionality in the DMwR [@DMwR] package. Dr. Cook wrote most of this code.

```{r impute.R}
source("../R/impute.R")
```

\clearpage

# Number of clusters

With groups 3 and 4 put together and imputed as above, It may be useful to attempt to determine the appropriate number of clusters. First, we consider wb.ratio, the ratio of average within-cluster Euclidian distance to average between-cluster Euclidian distance. Figure \ref{fig:wb-ratio} shows wb.ratio as a function of $k$, the number of clusters. We show results for kmeans with Euclidian distance (with the kmeans function in core R), the "partitioning around medoids" (pam) method with Manhattan distance in the cluster package [@cluster], and hierarchical clustering with several linkage methods (with the hclust function in core R). It is alarming that wb.ratio does not monotonically decrease with $k$, so any clustering analysis should be cautious. It is especially important to note that single, average, and centroid linkages should not be trusted, because here, wb.ratio mostly increases with increasing $k$. (And yet, for small $k$, these linkages with increasing wb.ratio outperform other methods for small $k$.) The ward linkage clusterings are the most believable because wb.ratio behaves almost as it should: except for some erratic behavior for small $k$, wb.ratio dips sharply and then starts to level off. There is no clear choice of $k$, though $k = 6$ marks the point where most of this erratic behavior stops and a gentle downward slope begins.


```{r num-clusters.R}
source("../R/num-clusters.R")
```

```{r wb-ratio-plot, fig.cap="\\label{fig:wb-ratio} wb.ratio as a function of $k$, the number of clusters. We show results for kmeans with Euclidian distance (with the kmeans function in core R), the \"partitioning around medoids\" (pam) method with Manhattan distance in the cluster package [@cluster], and hierarchical clustering with several linkage methods (with the hclust function in core R). It is alarming that wb.ratio does not monotonically decrease with $k$, so any clustering analysis should be cautious. It is especially important to note that single, average, and centroid linkages should not be trusted, since here, wb.ratio mostly with increasing $k$. (And yet, for small $k$, these linkages with increasing wb.ratio outperform other methods for small $k$.) The ward linkage clusterings are the most believable because wb.ratio behaves almost as it should: except for some erratic behavior for small $k$, wb.ratio dips sharply and then starts to level off. There is no clear choice of $k$, though $k = 6$ marks the point where most of this erratic behavior stops and a gentle downward slope begins."}
wb.ratio.plot()
```


We also look at dendrograms from hierarchical clustering to get a sense an optimal $k$, if we can determine $k$ at all. Figure \ref{fig:dendros} shows dendrograms from hierarchical clustering using six linkage methods. Only spring 2014 dendrograms are shown, as results for the other two semesters are similar. If we use ward linkage, arguably the most trustworthy choice in Figure \ref{fig:dendros} $k = 3$ is a reasonable choice. The other dendrograms are difficult to interpret. Single and centroid linkage dendrograms are nearly flat, and the complete and average dendrograms are likewise not definitive.  

```{r dendros, fig.cap="\\label{fig:dendros} We also look at dendrograms from hierarchical clustering to get a sense an optimal $k$, if we can determine $k$ at all. Figure \ref{fig:dendros} shows dendrograms from hierarchical clustering using six linkage methods. Only spring 2014 dendrograms are shown, as results for the other two semesters are similar. If we use ward linkage, arguably the most trustworthy choice in Figure \ref{fig:dendros} $k = 3$ is a reasonable choice. The other dendrograms are difficult to interpret. Single and centroid linkage dendrograms are nearly flat, and the complete and average dendrograms are likewise not definitive."}
dendros()
```





#Acknowledgements

We would like to thank Dr. Cook for her advice on dealing with missing values and her imputation code. Also, we used the R packages cluster [@cluster], DMwR [@DMwR], fpc [@fpc], ggplot2 [@ggplot2], gridExtra [@gridExtra], and reshape2 [@reshape2].

#References

